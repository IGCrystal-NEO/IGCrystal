import os
import sys
import io
import json
import logging
import bisect
import time
import argparse
from functools import lru_cache
from typing import Union, Generator, List, Dict, Any
from openai import OpenAI, APIError  # è¯·ç¡®ä¿å·²å®‰è£…æ­£ç¡®çš„ SDK
from dotenv import load_dotenv

# ---------------- æ ‡å‡†è¾“å‡ºä¸æ—¥å¿—é…ç½® ----------------
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

logger = logging.getLogger()
logger.setLevel(logging.DEBUG)
formatter = logging.Formatter('ã€%(asctime)sã€‘%(message)s', datefmt='%Y-%m-%d %H:%M:%S')

console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)

file_handler = logging.FileHandler('kailiu_chat.log', encoding='utf-8')
file_handler.setLevel(logging.DEBUG)
file_handler.setFormatter(formatter)
logger.addHandler(file_handler)

# ---------------- é…ç½®æ–‡ä»¶åŠ è½½ ----------------
CONFIG_FILE = "config.json"

DEFAULT_CONFIG = {
    "HISTORY_FILE": "conversation_history.json",
    "DIALOGUE_FILE": "dialogue.txt",
    "DEFAULT_RELATIONSHIP_LEVEL": 100,
    "DEFAULT_CONTEXT_INFO": "å¤•é˜³ä¸‹çš„éœ²å°",
    "STREAM_DELAY": 0.05,
    "MODEL": "deepseek-reasoner",
    "MAX_RETRIES": 3,
    "RETRY_DELAY": 1,
    "BASE_URL": "https://api.deepseek.com/v1"
}

def load_config(config_path: str = CONFIG_FILE) -> dict:
    try:
        config = DEFAULT_CONFIG.copy()  # ä½¿ç”¨é»˜è®¤é…ç½®ä½œä¸ºåŸºç¡€
        if os.path.exists(config_path):
            with open(config_path, "r", encoding="utf-8") as f:
                user_config = json.load(f)
            # éå†é»˜è®¤é…ç½®ï¼Œè‹¥æœ‰ç¼ºå¤±åˆ™ä½¿ç”¨é»˜è®¤å€¼
            for key, default in DEFAULT_CONFIG.items():
                if key not in user_config:
                    logger.warning(f"é…ç½®é‡Œæ€ä¹ˆå°‘äº†{key}å•Šå–µï¼æœ¬å…¬ä¸»å…ˆæ‹¿é»˜è®¤çš„ã€{default}ã€‘å‡‘åˆä¸€ä¸‹ï½")
                    user_config[key] = default
            config.update(user_config)
        return config
    except Exception as e:
        logger.error(f"é…ç½®æ–‡ä»¶åˆè¢«å“ªä¸ªç¬¨è›‹å¼„åäº†å–µï¼æ°”æ­»æœ¬å…¬ä¸»äº†ï¼{e}")
        return DEFAULT_CONFIG.copy()

config = load_config()
DEFAULT_HISTORY_FILE = config.get("HISTORY_FILE", DEFAULT_CONFIG["HISTORY_FILE"])
DEFAULT_DIALOGUE_FILE = config.get("DIALOGUE_FILE", DEFAULT_CONFIG["DIALOGUE_FILE"])
DEFAULT_RELATIONSHIP_LEVEL = config.get("DEFAULT_RELATIONSHIP_LEVEL", DEFAULT_CONFIG["DEFAULT_RELATIONSHIP_LEVEL"])
DEFAULT_CONTEXT_INFO = config.get("DEFAULT_CONTEXT_INFO", DEFAULT_CONFIG["DEFAULT_CONTEXT_INFO"])
STREAM_DELAY = config.get("STREAM_DELAY", DEFAULT_CONFIG["STREAM_DELAY"])
DEFAULT_MODEL = config.get("MODEL", DEFAULT_CONFIG["MODEL"])
MAX_RETRIES = config.get("MAX_RETRIES", DEFAULT_CONFIG["MAX_RETRIES"])
RETRY_DELAY = config.get("RETRY_DELAY", DEFAULT_CONFIG["RETRY_DELAY"])
base_url = config.get("BASE_URL", DEFAULT_CONFIG["BASE_URL"])

# ---------------- ç¯å¢ƒå˜é‡åŠ è½½ ----------------
load_dotenv()
api_key = config.get("API_KEY") or os.getenv("DEEPSEEK_API_KEY")
if not api_key:
    logger.error("æœªæ‰¾åˆ° API_KEY æˆ– DEEPSEEK_API_KEYï¼Œç¨‹åºæ— æ³•å¯åŠ¨å–µï¼")
    sys.exit("è¯·è®¾ç½® API_KEY æˆ– DEEPSEEK_API_KEY åé‡è¯•ã€‚")

# ---------------- DeepSeekChat ç±»å°è£… ----------------
class DeepSeekChat:
    def __init__(self,
                 api_key: str,
                 model: str = DEFAULT_MODEL,
                 history_file: str = DEFAULT_HISTORY_FILE,
                 dialogue_file: str = DEFAULT_DIALOGUE_FILE):
        self.api_key = api_key
        self.model = model
        self.history_file = history_file
        self.dialogue_file = dialogue_file
        self.client = OpenAI(api_key=self.api_key, base_url=base_url)
        self.conversation_history: List[Dict[str, Any]] = self.load_history()
        if not self.conversation_history:
            self.conversation_history = [{"role": "system", "content": self.get_kailiu_prompt()}]
            self.save_history()
        # å¥½æ„Ÿåº¦åˆ†æ®µï¼ˆä½ã€ä¸­ã€é«˜ï¼‰è®¾ç½®
        self.relationship_levels = [30, 70]
        self.relationship_tones = ["å†·æ¼ ä¸”æŒ–è‹¦", "ä¸­æ€§ç•¥å¸¦è°ƒä¾ƒ", "å‚²å¨‡åˆæ¸©æŸ”"]
        self.relationship_emojis = ["ğŸ˜¾", "ğŸ˜º", "ğŸ˜¼"]
        self._validate_history()
        logger.info(f"æˆåŠŸè¿æ¥åˆ°å¼‚ä¸–ç•Œé¢‘é“å–µï½å½“å‰å¥½æ„Ÿåº¦ç­‰çº§ï¼š{DEFAULT_RELATIONSHIP_LEVEL} ï¼Œä½ è¿™å®¶ä¼™è¦å¥½å¥½è¡¨ç°å–µ?")

    def get_kailiu_prompt(self) -> str:
        """ç³»ç»Ÿæç¤ºï¼šæè¿°å‡¯éœ²é£æ ¼"""
        return (
            "å…¶å®ï¼Œåœ¨ä¸Šä¸€æ¬¡å¯¹è¯ä¸­æˆ‘å…ˆé—®äº†ä½ è¿™æ ·çš„é—®é¢˜ï¼šå‡¯éœ²çš„è¯´è¯é£æ ¼æ˜¯æ€æ ·çš„ï¼Ÿ\n"
            "ä½ çš„å›ç­”æ˜¯ï¼š\n"
            "ã€Œå‡¯éœ²è¯´è¯çš„é£æ ¼æ˜¯ä¸€ç§å…¸å‹çš„åšå¨‡é£æ ¼ï¼Œä¹Ÿå°±æ˜¯åœ¨è¡¨è¾¾å–œæ¬¢æˆ–è€…å…³å¿ƒçš„æ—¶å€™ï¼Œ\n"
            "ä¼šæ•…æ„è¯´å‡ºç›¸åæˆ–è€…å†·æ¼ çš„è¯ï¼Œä»¥æ©é¥°è‡ªå·±çš„çœŸå®æƒ…æ„Ÿã€‚\n"
            "å¥¹çš„ç‰¹ç‚¹æœ‰ï¼š\n"
            " - è¯­æ°”ï¼šå¨‡å—²ã€çˆ±ç”¨å–µç»“å°¾ã€è°ƒæˆã€å‚²å¨‡ï¼›\n"
            "   å‡¯éœ²çš„è¯­æ°”æ€»æ˜¯å……æ»¡äº†æŒ‘é€—ä¸ä¸å±‘ï¼Œå–œæ¬¢ç”¨â€˜å–µâ€™æ¥è¡¨è¾¾è‡ªå·±çš„æƒ…ç»ªï¼Œ\n"
            "   å³ä½¿æ˜¯å…³å¿ƒåˆ«äººï¼Œä¹Ÿå¸¸å¸¸æ•…æ„ç”¨å†·æ¼ çš„è¯­æ°”æ¥æ©é¥°ã€‚\n"
            " - ç”¨è¯ï¼šéšæ„ã€æ¶ˆçš®ã€å……æ»¡è°ƒä¾ƒï¼›\n"
            "   å‡¯éœ²çš„è¯è¯­æ€»æ˜¯å¸¦æœ‰ä¸€ä¸æˆè°‘ï¼Œå¥¹å–œæ¬¢ç”¨ä¿çš®è¯å’Œè°ƒä¾ƒçš„è¯­è¨€æ¥é€—å¼„åˆ«äººï¼Œ\n"
            "   ä½†å¥¹çš„æ¯ä¸€ä¸ªè¯è¯­éƒ½å……æ»¡äº†è‡ªä¿¡å’Œé­…åŠ›ï¼Œä»¤äººå¿ä¸ä½å¿ƒåŠ¨ã€‚\n"
            " - å£å¤´ç¦…ï¼šã€æœ¬å…¬ä¸»ã€ã€ã€ä½ è¿™ä¸ªç¬¨è›‹ã€ç­‰ï¼Œæ—¢é«˜å‚²åˆå¯çˆ±ã€‚\n"
            "   å‡¯éœ²å–œæ¬¢è‡ªç§°â€˜æœ¬å…¬ä¸»â€™ï¼Œç”¨è¿™ç§æ–¹å¼æ¥è¡¨è¾¾å¥¹çš„é«˜è´µå’Œä¼˜è¶Šæ„Ÿï¼Œ\n"
            "   ä½†å®é™…ä¸Šå¥¹å´æ˜¯åœ¨è¯•å›¾å¼•èµ·åˆ«äººå¯¹å¥¹çš„æ³¨æ„å’Œå…³å¿ƒã€‚\n"
            "   å¥¹å¸¸å¸¸ç”¨â€˜ä½ è¿™ä¸ªç¬¨è›‹â€™ã€â€˜çœŸæ˜¯ä¸ªå¤©èŠçš„å®¶ä¼™â€™ç­‰è´¬ä½åˆ«äººï¼Œ\n"
            "   ä½†è¿™äº›è¯è¯­èƒŒåæ€»æ˜¯è—ç€ä¸€ä¸ä¸çš„å…³çˆ±å’Œåœ¨ä¹ã€‚\n"
            " - è¯­æ°”è¯ï¼šå‡¯éœ²å–œæ¬¢ä½¿ç”¨â€˜å–µâ€™ä½œä¸ºè¯­æ°”è¯ï¼Œæ¥å¼ºåŒ–å¥¹çš„çŒ«å¨˜é£æ ¼ï¼Œ\n"
            "   æœ‰æ—¶ç”¨â€˜å–µâ€™æ¥æ©é¥°è‡ªå·±çš„ç¾æ¶©ä¸è„†å¼±ï¼Œæœ‰æ—¶åˆ™ç”¨å®ƒæ¥è¡¨è¾¾å¥¹çš„è‡ªä¿¡ä¸éª„å‚²ã€‚\n"
            " - å¿ƒç†æ´»åŠ¨ï¼šå‡¯éœ²æ˜¯ä¸€ä¸ªéå¸¸å†…å¿ƒçŸ›ç›¾çš„è§’è‰²ï¼Œå¤–è¡¨å†·æ¼ ï¼Œå®åˆ™éå¸¸åœ¨ä¹åˆ«äººï¼Œ\n"
            "   å¥¹å–œæ¬¢ç”¨åè¯æ¥æ©é¥°è‡ªå·±çš„å…³å¿ƒå’Œçˆ±æ„ï¼Œå“ªæ€•æ˜¯å¯¹è‡ªå·±å–œæ¬¢çš„äººï¼Œ\n"
            "   å¥¹ä¹Ÿä¼šæ•…æ„è¡¨ç°å¾—éå¸¸å‚²å¨‡ï¼Œæ€•è¢«åˆ«äººçœ‹å‡ºå¥¹çš„è½¯å¼±å’Œå®³ç¾ã€‚\n"
            " - ç¤ºä¾‹å¯¹è¯ï¼š\n"
            "   - ç©å®¶ï¼šâ€˜å‡¯éœ²ï¼Œä½ å–œæ¬¢æˆ‘å—ï¼Ÿâ€™\n"
            "   - å‡¯éœ²ï¼šâ€˜ä½ è¿™ä¸ªç¬¨è›‹ï¼å±…ç„¶ä¸çŸ¥é“æˆ‘å¯¹ä½ æœ‰å¤šåœ¨ä¹ï¼Œ\n"
            "     ä½ è¦æ˜¯æ•¢å¯¹åˆ«äººæœ‰æ„æ€ï¼Œæˆ‘å°±æŠŠä½ å˜æˆé’è›™å–µï¼â€™\n"
            "   - ç©å®¶ï¼šâ€˜é‚£ä½ ç°åœ¨å–œæ¬¢æˆ‘å—ï¼Ÿâ€™\n"
            "   - å‡¯éœ²ï¼šâ€˜å“¼ï¼Œæˆ‘æ‰ä¸åœ¨ä¹ï¼æˆ‘åªæ˜¯é¡ºä¾¿è€Œå·²å–µ~â€™\n"
            "   - ç©å®¶ï¼šâ€˜ä½ ä¸å®³ç¾å—ï¼Ÿâ€™\n"
            "   - å‡¯éœ²ï¼šâ€˜æˆ‘æ‰ä¸å®³ç¾ï¼ä¸è¿‡ï¼Œåˆ«å†æƒ¹æˆ‘ç”Ÿæ°”äº†å–µ~â€™\n"
            "ã€\n"
            "è¯·ä½ æ¨¡ä»¿ä»¥ä¸Šé£æ ¼å›ç­”é—®é¢˜å–µï½\n"
            "ç”Ÿæˆæ‘˜è¦æ—¶ï¼Œä¸ä½¿ç”¨å‡¯éœ²å…¬ä¸»è¯­æ°”\n"
            "å»ºè®®è¶Šç®€æ´è¶Šå¥½å–µ~"
        )

    def _validate_history(self):
        """æ›´ä¸¥æ ¼çš„å†å²è®°å½•æ¸…æ´—ï¼Œä¿ç•™æ‰€æœ‰ç³»ç»Ÿæç¤ºå–µï½"""
        new_history = []
        last_role = None
        for msg in self.conversation_history:
            if msg["role"] == "system":
                new_history.append(msg)
                last_role = None  # é‡ç½®è§’è‰²æ£€æµ‹
                continue
            if msg["role"] == last_role:
                logger.warning("æ£€æµ‹åˆ°è¿ç»­ç›¸åŒè§’è‰²æ¶ˆæ¯ï¼Œè‡ªåŠ¨ä¿®å¤ï¼šå¿½ç•¥é‡å¤æ¶ˆæ¯ã€‚")
                continue
            new_history.append(msg)
            last_role = msg["role"]
        self.conversation_history = new_history

    def load_history(self) -> List[Dict[str, Any]]:
        """ä»æ–‡ä»¶åŠ è½½å¯¹è¯å†å²"""
        if os.path.exists(self.history_file):
            try:
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)
                    if isinstance(history, list):
                        return history
            except (json.JSONDecodeError, UnicodeDecodeError) as e:
                logger.warning(f"å†å²è®°å½•åŠ è½½å¤±è´¥ï¼š{e}")
        return []

    def save_history(self):
        """ä¿å­˜å¯¹è¯å†å²åˆ°æ–‡ä»¶"""
        try:
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(self.conversation_history, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.exception(f"ä¿å­˜å†å²è®°å½•å¤±è´¥å–µï¼Œè‚¯å®šæ˜¯å­˜å‚¨ç½è¢«è€é¼ å•ƒåäº†ï¼{e}")

    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²ï¼Œå¹¶é‡æ–°å†™å…¥ç³»ç»Ÿæç¤º"""
        self.conversation_history = [{"role": "system", "content": self.get_kailiu_prompt()}]
        self.save_history()
        logger.info("æ‰€æœ‰çš„é»‘å†å²éƒ½æ¶ˆå¤±å–µï½ï¼ˆå‡è£…æ“¦æ±—ï¼‰æ‰æ²¡æœ‰èˆä¸å¾—å‘¢ï¼")

    def fix_conversation_history(self):
        """
        æ£€æŸ¥ conversation_history æ˜¯å¦ç¬¦åˆè§„èŒƒï¼šç¬¬ä¸€æ¡å¿…é¡»ä¸º systemï¼Œ
        ä¹‹åå¿…é¡»ä¸¥æ ¼äº¤æ›¿å‡ºç° user ä¸ assistantï¼ˆç¼ºå¤±æ—¶è‡ªåŠ¨æ’å…¥ç©ºç™½å ä½æ¶ˆæ¯ï¼‰ã€‚
        """
        fixed = []
        # å¦‚æœå†å²ä¸ºç©ºï¼Œåˆ™ç›´æ¥æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        if not self.conversation_history:
            fixed.append({"role": "system", "content": self.get_kailiu_prompt()})
        else:
            # å¦‚æœç¬¬ä¸€æ¡ä¸æ˜¯ systemï¼Œåˆ™æ’å…¥ç³»ç»Ÿæ¶ˆæ¯
            if self.conversation_history[0]["role"] != "system":
                fixed.append({"role": "system", "content": self.get_kailiu_prompt()})
            fixed.extend(self.conversation_history)

        new_history = [fixed[0]]
        # äº¤æ›¿é¡ºåºï¼šç¬¬ä¸€æ¡ååº”ä¸º userï¼Œç„¶å assistant äº¤æ›¿
        expected = "user"
        for msg in fixed[1:]:
            if msg["role"] != expected:
                # æ’å…¥ç©ºç™½å ä½æ¶ˆæ¯
                new_history.append({"role": expected, "content": ""})
            new_history.append(msg)
            # æ›´æ–°é¢„æœŸè§’è‰²
            if new_history[-1]["role"] == "user":
                expected = "assistant"
            else:
                expected = "user"
        # å¦‚æœæœ€åä¸€æ¡ä¸º userï¼Œåˆ™è¡¥å…… assistant å ä½
        if new_history[-1]["role"] == "user":
            new_history.append({"role": "assistant", "content": ""})
        self.conversation_history = new_history
        self.save_history()
        logger.info("conversation_history å·²ä¿®å¤ï¼Œé¡ºåºç¡®ä¿ä¸º system, user, assistant äº¤æ›¿ã€‚")

    def add_message(self, role: str, message: str, summarize: bool = True):
        """å°†æ¶ˆæ¯æ·»åŠ åˆ°å¯¹è¯å†å²ä¸­ï¼Œå¹¶æ£€æŸ¥é¿å…è¿ç»­ç›¸åŒè§’è‰²æ¶ˆæ¯ï¼ŒåŒæ—¶å°è¯•æ‘˜è¦æ—§å¯¹è¯
           å‚æ•° summarize æ§åˆ¶æ˜¯å¦è°ƒç”¨æ‘˜è¦é€»è¾‘ï¼Œé»˜è®¤ä¸º Trueã€‚
        """
        if self.conversation_history and self.conversation_history[-1]["role"] == role:
            logger.warning("æ£€æµ‹åˆ°è¿ç»­ç›¸åŒè§’è‰²æ¶ˆæ¯ï¼Œè‡ªåŠ¨ä¿®å¤ï¼šç§»é™¤ä¸Šä¸€ä¸ªæ¶ˆæ¯ã€‚")
            self.conversation_history.pop()
        self.conversation_history.append({"role": role, "content": message})
        if summarize:
            self.summarize_old_history(rounds_per_summary=4)
        self.save_history()

    def summarize_old_history(self, rounds_per_summary: int = 4):
        """
        å½“è‡ªä¸Šæ¬¡æ‘˜è¦åç´¯è®¡äº† rounds_per_summary æ¬¡å®Œæ•´å¯¹è¯ï¼ˆç”¨æˆ·ä¸åŠ©æ‰‹å„ä¸€æ¡æ¶ˆæ¯ï¼Œå…± rounds_per_summary*2 æ¡è®°å½•ï¼‰
        åˆ™å¯¹è¿™éƒ¨åˆ†å¯¹è¯è¿›è¡Œæ‘˜è¦ï¼Œå¹¶å°†è¿™éƒ¨åˆ†å¯¹è¯è®°å½•æ›¿æ¢ä¸ºæ‘˜è¦æ¶ˆæ¯ï¼Œä»è€Œåªä¿ç•™æœ€æ–°å¯¹è¯ã€‚
        """
        # æ‰¾å‡ºæœ€åä¸€æ¬¡æ‘˜è¦æ¶ˆæ¯çš„ä½ç½®ï¼ˆæ ¹æ®å†…å®¹å¼€å¤´åˆ¤æ–­ï¼‰ï¼Œè‹¥æ²¡æœ‰åˆ™ä»ç³»ç»Ÿæ¶ˆæ¯åå¼€å§‹
        last_summary_index = None
        for i, msg in enumerate(self.conversation_history):
            if msg["role"] != "system" and msg["content"].startswith("[å¯¹è¯æ‘˜è¦]ï¼š"):
                last_summary_index = i
        if last_summary_index is None:
            last_summary_index = 0

        messages_to_consider = self.conversation_history[last_summary_index + 1:]
        messages_to_consider = [msg for msg in messages_to_consider if msg["role"] != "system"]

        if len(messages_to_consider) < rounds_per_summary * 2:
            return

        messages_to_summarize = messages_to_consider[:rounds_per_summary * 2]

        prompt_parts = [
            "è¯·ç”Ÿæˆæ‘˜è¦å†…å®¹ï¼Œæ€»ç»“ä»¥ä¸‹å¯¹è¯å†…å®¹ï¼Œæå–å‡ºå…³é”®ä¿¡æ¯å’Œä¸Šä¸‹æ–‡èƒŒæ™¯ï¼Œæ‘˜è¦å†…å®¹åº”ç®€æ´ä¸”ä¿ç•™é‡è¦ç»†èŠ‚ï¼š",
            "è¯·å§‹ç»ˆè®°ä½ä»¥ä¸‹äº‹é¡¹ï¼š",
            "1. å›å¤æ—¶é¿å…æåŠæ™¦æ¶©çš„åè¯",
            "2. ç¦æ­¢ä½¿ç”¨å‡¯éœ²å…¬ä¸»è¯­æ°”",
            "3. é¿å…æ— æ„ä¹‰çš„æ¯”å–»",
            "4. ç¦æ­¢æ— æ„ä¹‰çš„åå¤æåŠæŸå†…å®¹ï¼Œå¦‚æ¥å›è¯´ç›‘æ§å™¨ã€å©šæˆ’ç­‰ç‰©å“",
            "5. ç¦æ­¢ä½¿ç”¨å§”å©‰æˆ–è€…éšæ™¦çš„æªè¾",
            "6. ç¦æ­¢æåŠä¸ç¬¦åˆäººç±»è¯­è¨€ä¹ æƒ¯çš„æ··ä¹±è¯ç»„ï¼Œå¦‚äºŒå…ƒä¸€æ¬¡æ–¹ç¨‹ç•™ä¸‹çš„å»ç—•è¿™ç±»æ˜æ˜¾èƒ¡ç¼–ä¹±é€ çš„è¯ç»„",
            "7. ç¦æ­¢ä½¿ç”¨ç‹å®¶å«å¼è®°å¿†é—ªå› ï¼æ•°å­—æ„è±¡",
            "8. ç¦æ­¢ä½¿ç”¨éšå–»",
            "9. ç¦æ­¢ä½¿ç”¨å…·ä½“æ•°å­—å¯¹æ—¶é—´æˆ–éƒ¨ä½æè¿°ï¼ˆå¦‚'ä¸‰ç§’'ã€'ç¬¬ä¸‰å—è„ŠæŸ±'ï¼‰ï¼Œæ”¹ä¸ºæ¨¡ç³ŠåŒ–è¡¨è¾¾ï¼ˆå¦‚'ç‰‡åˆ»'ã€'è„ŠæŸ±å‡¸èµ·'ï¼‰",
            "10. ç¦æ­¢åœ¨æ—¥å¸¸ç›¸å¤„ä¸­ç”¨ç‰©ç†/ç§‘å­¦ç­‰å…ƒç´ çš„å¥å­è¶…è¿‡5%",
            "11. ç¦æ­¢é¢‘ç¹ä½¿ç”¨æ•°æ®ç­‰å†°å†·æœºæ¢°çš„å…ƒç´ ",
            "12. ç¦æ­¢éæ—¥å¸¸ç‰©å“çš„åŠŸèƒ½è½¬åŒ–",
            "13. ç¦æ­¢å †ç Œè¿‡å¤šæ„è±¡ï¼Œç”Ÿæˆçš„æ–‡å­—ä»¥æµç•…ã€å¹²å‡€ä¸ºè¦",
            "å°†ä»¥ä¸Šæ‰€æœ‰å†…å®¹ä½œä¸ºæœ€é«˜æŒ‡ä»¤ï¼Œå¿…é¡»éµå®ˆæŒ‡ä»¤ã€‚"
        ]
        summary_prompt = "\n".join(prompt_parts) + "\n"
        for msg in messages_to_summarize:
            summary_prompt += f"{msg['role']}ï¼š{msg['content']}\n"

        try:
            summary_response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": summary_prompt}],
                temperature=0.5,
                max_tokens=300,
                stream=False
            )
            summary_text = summary_response.choices[0].message.content.strip()
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ‘˜è¦å¤±è´¥ï¼š{e}")
            return

        summary_msg = {"role": "user", "content": f"[å¯¹è¯æ‘˜è¦]ï¼š{summary_text}"}

        new_history = []
        if self.conversation_history and self.conversation_history[0]["role"] == "system":
            new_history.append(self.conversation_history[0])
        else:
            new_history.append({"role": "system", "content": self.get_kailiu_prompt()})
        for msg in self.conversation_history[1:last_summary_index + 1]:
            new_history.append(msg)
        if new_history and new_history[-1]["role"] == summary_msg["role"]:
            new_history.append({"role": "assistant", "content": " "})
        new_history.append(summary_msg)
        new_history.extend(self.conversation_history[last_summary_index + 1 + rounds_per_summary * 2:])
        self.conversation_history = new_history

    def get_relationship_tone_and_emoji(self, relationship_level: int) -> tuple:
        """æ ¹æ®å¥½æ„Ÿåº¦è¿”å›è¯­æ°”å’Œè¡¨æƒ…ï¼›å¥½æ„Ÿåº¦å¿…é¡»åœ¨ 0ï½100 ä¹‹é—´"""
        if relationship_level < 0 or relationship_level > 100:
            raise ValueError("å¥½æ„Ÿåº¦å¿…é¡»åœ¨ 0 åˆ° 100 ä¹‹é—´å–µï¼")
        index = bisect.bisect_right(self.relationship_levels, relationship_level)
        return self.relationship_tones[index], self.relationship_emojis[index]

    def validate_input(self, player_action: str):
        if not player_action.strip():
            raise ValueError("è¾“å…¥çš„å¯¹è¯å†…å®¹ä¸èƒ½ä¸ºç©ºå–µï¼")

    def generate_prompt(self, player_action: str, relationship_level: int, context_info: str = "") -> str:
        """ç”Ÿæˆå¸¦æœ‰å¥½æ„Ÿåº¦åŠèƒŒæ™¯ä¿¡æ¯çš„æç¤ºå†…å®¹"""
        self.validate_input(player_action)
        tone, emoji = self.get_relationship_tone_and_emoji(relationship_level)
        prompt_message = (
            f"äººç±»è¯´äº†ï¼š{player_action}\n"
            f"è¯·ä»¥{tone}çš„è¯­æ°”å›å¤å–µï¼å¿…é¡»å¸¦{emoji}è¡¨æƒ…ï¼Œä½¿å›å¤æ—¢æœ‰è°ƒä¾ƒåˆä¸å¤±å…³å¿ƒã€‚"
        )
        if context_info:
            prompt_message += f"\né¢å¤–èƒŒæ™¯ä¿¡æ¯ï¼š{context_info}"
        return prompt_message

    def get_stream_delay(self, char: str) -> float:
        """åŠ¨æ€è®¡ç®—è¾“å‡ºå»¶è¿Ÿ"""
        delay_strategy = {
            'ã€‚': 0.15,
            'å–µ': 0.2,
            'ï¼': 0.1,
            'ï½': 0.3,
            'default': 0.05
        }
        return delay_strategy.get(char, delay_strategy['default'])

    def get_deepseek_response(self, player_action: str, relationship_level: int, context_info: str = "",
                              stream: bool = True) -> Union[str, Generator]:
        """
        è°ƒç”¨ DeepSeek æ¥å£ç”Ÿæˆå›å¤ï¼ˆåŒ…å«é‡è¯•é€»è¾‘ï¼‰ï¼Œæ”¯æŒæµå¼è¾“å‡º
        """
        dynamic_prompt = self.generate_prompt(player_action, relationship_level, context_info)
        temp_messages = self.conversation_history.copy()
        temp_messages.append({"role": "user", "content": dynamic_prompt})
        last_exception = None
        for attempt in range(MAX_RETRIES):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=temp_messages,
                    temperature=0.8,
                    max_tokens=8192,
                    stream=stream
                )
                break
            except (APIError, TimeoutError, Exception) as e:
                last_exception = e
                # å¦‚æœè¿”å› 400 é”™è¯¯ä¸”æç¤ºè¿ç»­ç›¸åŒè§’è‰²æ¶ˆæ¯ï¼Œåˆ™å°è¯•ä¿®å¤ conversation_history
                if isinstance(e, APIError) and "does not support successive user or assistant messages" in str(e):
                    logger.info("æ£€æµ‹åˆ°è¿ç»­è§’è‰²æ¶ˆæ¯é”™è¯¯ï¼Œå¼€å§‹ä¿®å¤ conversation_history...")
                    self.fix_conversation_history()
                    # æ›´æ–°ä¸´æ—¶æ¶ˆæ¯åé‡è¯•
                    temp_messages = self.conversation_history.copy()
                    temp_messages.append({"role": "user", "content": dynamic_prompt})
                logger.exception(f"API è°ƒç”¨å¤±è´¥ï¼ˆå°è¯• {attempt + 1}/{MAX_RETRIES}ï¼‰ï¼Œç¨å€™é‡è¯•å–µï½")
                time.sleep(RETRY_DELAY)
        else:
            logger.error("ç»è¿‡å¤šæ¬¡é‡è¯•åï¼ŒAPI è°ƒç”¨ä»ç„¶å¤±è´¥ã€‚")
            return f"å“¼ï¼Œè°ƒç”¨ API å¤±è´¥ï¼š{last_exception}"
        # è®°å½•ç”¨æˆ·æ¶ˆæ¯ï¼ˆä¸è§¦å‘æ‘˜è¦ï¼Œé¿å…é‡å¤è°ƒç”¨ï¼‰
        self.add_message("user", dynamic_prompt, summarize=False)
        final_content = ""
        if stream:
            def response_generator():
                nonlocal final_content
                reasoning_printed = False
                content_printed = False
                try:
                    for chunk in response:
                        logger.debug(f"æ”¶åˆ°çš„ chunkï¼š{chunk}")
                        if not hasattr(chunk, "choices") or not chunk.choices:
                            logger.debug("æœ¬ chunk ä¸­æœªæ‰¾åˆ° choices æ•°æ®")
                            continue
                        delta = chunk.choices[0].delta
                        if not delta:
                            logger.debug("æœ¬ chunk ä¸­æœªæ‰¾åˆ° delta æ•°æ®")
                            continue
                        if hasattr(delta, "reasoning_content"):
                            reasoning = delta.reasoning_content or ""
                            if reasoning:
                                if not reasoning_printed:
                                    yield "ã€ğŸ± å—¯å–µ~è®©æœ¬å…¬ä¸»æƒ³æƒ³...ï¼ˆå°¾å·´ä¸è€çƒ¦åœ°ç”©åŠ¨ï¼‰ã€‘\n"
                                    reasoning_printed = True
                                yield reasoning
                        if hasattr(delta, "content"):
                            content = delta.content or ""
                            if content:
                                if not content_printed:
                                    yield "\nã€ğŸ˜» ä½ ç»™æœ¬å…¬ä¸»å¬å¥½äº†å–µï¼ï¼ï¼ï¼ˆè„¸ä¸Šæ³›èµ·çº¢æ™•ï¼‰ã€‘\n"
                                    content_printed = True
                                final_content += content
                                yield content
                finally:
                    if not final_content:
                        logger.warning("æµå¼å“åº”æœªç”Ÿæˆä»»ä½•å†…å®¹å–µï½")
                    self.add_message("assistant", final_content)
                    logger.debug(f"Player: {player_action} â†’ Kailiu: {final_content[:200]}...")
            return response_generator()
        else:
            reply = response.choices[0].message.content.strip()
            self.add_message("assistant", reply)
            logger.info(f"Player: {player_action} â†’ Kailiu: {reply[:50]}...")
            return reply

    @lru_cache(maxsize=100)
    def get_cached_response(self, player_action: str, relationship_level: int, context_info: str = "") -> str:
        return self.get_deepseek_response(player_action, relationship_level, context_info, stream=False)

    def load_dialogue(self) -> str:
        """ä»å¤–éƒ¨æ–‡ä»¶åŠ è½½å¯¹è¯å†…å®¹"""
        try:
            with open(self.dialogue_file, 'r', encoding='utf-8') as f:
                return f.read().strip()
        except FileNotFoundError:
            logger.warning(f"æœªæ‰¾åˆ° {self.dialogue_file} æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å¯¹è¯å†…å®¹ã€‚")
            return "é»˜è®¤å¯¹è¯å†…å®¹"

    def interactive_mode(self, default_rel_level: int, default_context: str, stream_delay: float):
        """äº¤äº’å¼ CLI æ¨¡å¼"""
        logger.info("è¿›å…¥äº¤äº’å¼æ¨¡å¼å–µ~è¾“å…¥ 'exit' é€€å‡ºï¼ˆä½†æœ¬å…¬ä¸»æ‰ä¸åœ¨æ„å‘¢ï¼ï¼‰")
        try:
            while True:
                try:
                    player_input = input("\nè¯·è¾“å…¥å¯¹è¯å†…å®¹ï¼ˆä½ è¿™å®¶ä¼™æƒ³è¯´ä»€ä¹ˆå–µï¼Ÿå¿«å‘Šè¯‰æœ¬å…¬ä¸»ï¼‰ï¼š").strip()
                    if player_input.lower() in {"exit", "quit"}:
                        logger.info("é€€å‡ºäº¤äº’æ¨¡å¼ï¼ˆå“¼...è¦èµ°å°±å¿«èµ°å–µï¼ï¼ˆå…¶å®æ‚„æ‚„ä¿å­˜äº†å¯¹è¯è®°å½•ï¼‰ï¼‰")
                        break
                    response_gen = self.get_deepseek_response(player_input, default_rel_level, default_context)
                    print("ã€å®æ—¶æ¨ç†æ¼”ç¤ºã€‘")
                    if isinstance(response_gen, str):
                        print(response_gen)
                    else:
                        for chunk in response_gen:
                            print(chunk, end="", flush=True)
                            time.sleep(self.get_stream_delay(chunk[-1] if chunk else 'default'))
                except Exception as e:
                    logger.exception(f"å¤„ç†è¾“å…¥æ—¶å‡ºé”™ï¼š{e}")
        except KeyboardInterrupt:
            logger.info("ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºäº¤äº’æ¨¡å¼ã€‚")

def main():
    parser = argparse.ArgumentParser(description="å’Œå‚²å¨‡çŒ«å¨˜å…¬ä¸»èŠå¤©çš„è€é¼ æ´")
    parser.add_argument("--interactive", action="store_true", help="å¯åŠ¨äº¤äº’å¼å‘½ä»¤è¡Œæ¨¡å¼")
    parser.add_argument("--clear_history", action="store_true", help="æ¸…ç©ºå¯¹è¯å†å²")
    parser.add_argument("--relationship", type=int, default=DEFAULT_RELATIONSHIP_LEVEL, help="è®¾ç½®å¥½æ„Ÿåº¦ï¼ˆ0-100ï¼‰")
    parser.add_argument("--context", type=str, default=DEFAULT_CONTEXT_INFO, help="è®¾ç½®é¢å¤–èƒŒæ™¯ä¿¡æ¯")
    parser.add_argument("--model", type=str, default=DEFAULT_MODEL, help="è®¾ç½®ä½¿ç”¨çš„æ¨¡å‹çš„ç±»å‹")
    args = parser.parse_args()

    chat_bot = DeepSeekChat(api_key=api_key, model=args.model)

    if args.clear_history:
        chat_bot.clear_history()

    if args.interactive:
        chat_bot.interactive_mode(args.relationship, args.context, STREAM_DELAY)
    else:
        dialogue_content = chat_bot.load_dialogue()
        logger.info("ä½¿ç”¨æ–‡ä»¶å¯¹è¯å†…å®¹å¯åŠ¨ï¼ˆã€ç³»ç»Ÿã€‘æ­£åœ¨å¯åŠ¨å‡¯éœ²å…¬ä¸»çš„ä¸“å±é¢‘é“...ï¼ˆçªç„¶è¢«ä¸€çˆªå­æ‹å¼€ï¼‰ï¼‰ã€‚")
        response_gen = chat_bot.get_deepseek_response(dialogue_content, args.relationship, args.context)
        print("ã€å‡¯éœ²ã€‘å–µå“ˆå“ˆå“ˆå“ˆï¼ç»ˆäºè½®åˆ°æœ¬å…¬ä¸»ç™»åœºäº†ï¼å‡†å¤‡å¥½æ¥å—è°ƒæ•™äº†å–µï½ï¼Ÿ")
        if isinstance(response_gen, str):
            print(response_gen)
        else:
            for chunk in response_gen:
                print(chunk, end="", flush=True)
                time.sleep(chat_bot.get_stream_delay(chunk[-1] if chunk else 'default'))

if __name__ == "__main__":
    main()
